{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape : (42000, 785)\n",
      "Test shape  : (42000, 785)\n"
     ]
    }
   ],
   "source": [
    "# Create df's from csv files\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "# Check size (Train df has one additional column which is label)\n",
    "print(f'Train shape : {train_df.shape}')\n",
    "print(f'Test shape  : {train_df.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting training df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features shape : (33600, 784)\n",
      "Train labels shape  : (33600,)\n",
      "Validation features shape : (8400, 784)\n",
      "Validation labels shape  : (8400,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and validation sets\n",
    "# The features for training are all columns starting from the second column\n",
    "# The target variable is the 'label' column\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_df.iloc[:, 1:], train_df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the training and validation sets\n",
    "print(f'Train features shape : {X_train.shape}')\n",
    "print(f'Train labels shape  : {y_train.shape}')\n",
    "print(f'Validation features shape : {X_val.shape}')\n",
    "print(f'Validation labels shape  : {y_val.shape}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide each element by 255 to normalize the pixel values to a range between 0 and 1\n",
    "X_train = X_train/255\n",
    "X_val = X_val/255\n",
    "test_df = test_df/255"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features shape : (33600, 28, 28, 1)\n",
      "Train labels shape  : (33600, 10)\n",
      "Validation features shape : (8400, 28, 28, 1)\n",
      "Validation labels shape  : (8400, 10)\n",
      "Test features shape : (28000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# The reshaping is performed to match the input shape requirements of Convolutional Neural Networks (CNNs)\n",
    "X_train = X_train.to_numpy().reshape(-1,28,28,1)\n",
    "X_val = X_val.to_numpy().reshape(-1,28,28,1)\n",
    "test_df = test_df.to_numpy().reshape(-1,28,28,1)\n",
    "# Print the shapes of the training and validation sets\n",
    "print(f'Train features shape : {X_train.shape}')\n",
    "print(f'Train labels shape  : {y_train.shape}')\n",
    "print(f'Validation features shape : {X_val.shape}')\n",
    "print(f'Validation labels shape  : {y_val.shape}')\n",
    "print(f'Test features shape : {test_df.shape}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# First Convolutional layer with 32 filters, each with a 3x3 kernel and ReLU activation\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "# Second Convolutional layer with 64 filters, each with a 3x3 kernel and ReLU activation\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "# MaxPooling layer with a pool size of 2x2\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Dropout layer with a rate of 0.25\n",
    "model.add(Dropout(0.25))\n",
    "# Third Convolutional layer with 128 filters, each with a 3x3 kernel and ReLU activation\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "# Another MaxPooling layer with a pool size of 2x2\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Another Dropout layer with a rate of 0.25\n",
    "model.add(Dropout(0.25))\n",
    "# Flatten layer to convert the 2D feature maps into a 1D feature vector\n",
    "model.add(Flatten())\n",
    "# Fully connected Dense layer with 256 units and ReLU activation\n",
    "model.add(Dense(256, activation='relu'))\n",
    "# Dropout layer with a rate of 0.5\n",
    "model.add(Dropout(0.5))\n",
    "# Output Dense layer with 10 units (for 10 classes) and softmax activation\n",
    "model.add(Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.1, zoom_range=0.1, fill_mode='nearest')\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 18:30:10.121132: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=128), epochs=3, validation_data=(\n",
    "    X_val, y_val), verbose=0, steps_per_epoch=X_train.shape[0] // 128)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 4s 15ms/step - loss: 0.0401 - accuracy: 0.9865\n",
      "Validation loss: 0.0401\n",
      "Validation accuracy: 0.9865\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_val, y_val)\n",
    "print(f'Validation loss: {loss:.4f}')\n",
    "print(f'Validation accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875/875 [==============================] - 12s 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 0, 9, ..., 3, 9, 2])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(test_df)\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display 3 first images from test_df to check model accuracy\n",
    "data = pd.read_csv('data/test.csv')\n",
    "for i in range(3):\n",
    "    # Get pixel values\n",
    "    pixels = data.values[i]\n",
    "\n",
    "    # Reshape pixel values into a 2D array\n",
    "    image = np.reshape(pixels, (28, 28))\n",
    "\n",
    "    # Display the image\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
